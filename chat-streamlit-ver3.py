import streamlit as st
import os, time, openai
from langchain_openai import OpenAIEmbeddings,ChatOpenAI
from langchain.schema import (SystemMessage, HumanMessage, AIMessage)
# from langchain.chat_models import ChatOpenAI
# from langchain.prompts import PromptTemplate
# from langchain.callbacks.base import BaseCallbackHandler
# from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.vectorstores.chroma import Chroma
from langchain.memory import ConversationBufferMemory
from save_chat_log import save_chat_log, get_device_info
from scenario_based_answer import load_scenarios, get_response_from_scenario, append_to_scenario, get_closest_match
# from langchain.chains import RetrievalQA

# OpenAI APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿
with open("api_key.txt", "r") as file:
    global OPENAI_API_KEY 
    OPENAI_API_KEY = file.read().strip()
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# ãƒãƒ£ãƒƒãƒˆGPTã®ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
gpt_model = "gpt-4o-mini"
# gpt_model = "gpt-4o"

# åˆæœŸç”»é¢è¡¨ç¤º
def init_page():
    st.set_page_config(
        page_title="BelxChatBot",
        page_icon="ğŸ¤—"
    )
    st.header("BelxChatBot ğŸ¤—")

# åˆæœŸåŒ–
def init_state():
    if 'stop' not in st.session_state:
        st.session_state['stop'] = False
    if 'chat_message' not in st.session_state:
        st.session_state.chat_message = []
        st.session_state['messages'] = [SystemMessage(content="è³ªå•ã‚’ã©ã†ã")]
    if 'history' not in st.session_state:
        st.session_state['history'] = []
    if 'chat_history' not in st.session_state:
        st.session_state['history'] = []
    if 'feedback' not in st.session_state:
        st.session_state['feedback'] = []

@st.cache_resource
def save_memory(userid):
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    return memory

def main():
    init_page()
    init_state()

    # å¿œç­”åœæ­¢ãƒœã‚¿ãƒ³
    if st.sidebar.button('å¿œç­”åœæ­¢'):
        st.session_state['stop'] = True

    # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.sidebar.button("å±¥æ­´ã‚¯ãƒªã‚¢"):
        st.session_state['feedback']=[]
        st.session_state.messages = [
            SystemMessage(content="è³ªå•ã‚’ã©ã†ã")
        ]
        st.session_state.costs = []

    # LLMãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®è¨­å®š
    llm = ChatOpenAI(
        temperature=0.2, 
        model_name=gpt_model,
        streaming=True, 
    )

    # å›ç­”ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹
    def conversational_chat(query):
        computer_name, user_name, local_ip_address = get_device_info()
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«è¨­å®š
        embeddings = OpenAIEmbeddings()
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢è¨­å®š
        vectorstore = Chroma(embedding_function=embeddings, persist_directory="./chroma_db")
        query = "ä»¥ä¸‹ã®è³ªå•ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ä¸‹ã•ã„ã€‚å›ç­”ãŒå¾—ã‚‰ã‚Œãªã‹ã£ãŸå ´åˆã¯ã€ã€Œå›ç­”NGã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚" + query
        # chat_qa = ConversationalRetrievalChain(
        # retrieverã®è¨­å®šã‚’å¤‰æ›´
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
         # ãƒ¡ãƒ¢ãƒªã®è¨­å®š
        # memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

        chat_qa = ConversationalRetrievalChain.from_llm(
            llm,
            retriever,
            # vectorstore.as_retriever(),
            # memory=memory,
            return_source_documents=True,
            # return_vector_score=True,
            )

    #     chat_qa = RetrievalQA.from_chain_type(
    #     llm=llm,
    #     chain_type="stuff",
    #     retriever=vectorstore.as_retriever(),
    #     return_source_documents=True
    # )
        
        vectordbkwargs = {"search_distance": 0.9}
        result = chat_qa({'question': query, 'chat_history':st.session_state['history'],"vectordbkwargs": vectordbkwargs})
        # result = chat_qa({'query':query})
        print(f"æ¤œç´¢çµæœ:{result}")


        # ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã®å®Ÿé¨“
        # ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã®å–å¾—æ–¹æ³•ã‚’å¤‰æ›´
        if 'source_documents' in result and result['source_documents']:
            for doc in result['source_documents']:
                print(f"å›ç­”: {doc.page_content}")
                if hasattr(doc, 'metadata') and 'score' in doc.metadata:
                    print(f"ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦: {doc.metadata['score']}")
                else:
                    print("ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯ã‚¹ã‚³ã‚¢ãŒã‚ã‚Šã¾ã›ã‚“")

        # if 'vector_similarity' in result:
        #     for doc, similarity in zip(result['source_documents'], result['vector_similarity']):
        #         print(f"å›ç­”: {doc.text}")
        #         print(f"ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦: {similarity}")
        else:
            print("ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ãŒæ¤œå‡ºã§ãã¾ã›ã‚“")

        if 'source_documents' in result:
            source_documents = result['source_documents']
        # å„Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®metadataã‹ã‚‰sourceã‚’å–å¾—
            sources = []
            similarities = []
            for doc in source_documents:
                if 'source' in doc.metadata:
                    source = doc.metadata['source']
                    if source not in sources:
                        sources.append(source)
                    if 'similarity' in doc.metadata:
                        similarities.append(doc.metadata['similarity'])
            # sources = set(doc.metadata['source'] for doc in source_documents if 'source' in doc.metadata)
            print(similarities)
            sources_str = '\n'.join(sources)  # sourcesãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            print('å›ç­”ã«ã‚ãŸã£ã¦ã¯ã€ä»¥ä¸‹ã‚’å‚è€ƒã«ã—ã¦ã„ã¾ã™ã€‚\n', sources_str)
            answer_with_sources = f"{result['answer']} (å›ç­”ã«ã‚ãŸã£ã¦ã¯ã€ä»¥ä¸‹ã‚’å‚è€ƒã«ã—ã¦ã„ã¾ã™ã€‚: {sources_str})"
        else:
            print('source_documentsãŒçµæœã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚')

        st.session_state['history'].append((query, answer_with_sources))
        return answer_with_sources

    # å›ç­”ãŒãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«ç„¡ã„å ´åˆã®ä¼šè©±
    def conversational_chat_whth_fallback(user_input):
        response = conversational_chat(user_input)
        if "å›ç­”NG" in response or "ãŠæ‰‹ä¼ã„ã§ãã¾ã›ã‚“" in response or "å›ç­”ã§ãã¾ã›ã‚“" in response:
            print('ç¤¾å†…ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«å›ç­”ãŒç„¡ã„ã®ã§ã€ãƒãƒ£ãƒƒãƒˆGPTãŒå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™')
            response = get_chatgpt_response(user_input)
        return response
    
    # ChatGPTã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆ
    def get_chatgpt_response(message):
        try:
            completion = openai.chat.completions.create(
            model=gpt_model,
             messages=[
                {"role": "user", "content": \
                 "ã‚ãªãŸã¯ç¤¾å†…ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®æ¡ˆå†…ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ãŒã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«ãªã„è³ªå•ã«å¯¾ã™ã‚‹\
                 å›ç­”ã‚’è¡Œã„ã¾ã™ã€‚å†’é ­ã«ã€Œç¤¾å†…ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«å›ç­”ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆGPTãŒä¸€èˆ¬çš„ãªå›ç­”ã‚’è¡Œã„ã¾ã™ã€\
                ã¨å‰ç½®ãã—ã¦ã‹ã‚‰å›ç­”ã—ã¦ãã ã•ã„",},
                {"role": "user", "content": message}
                ],
            max_tokens=1000, # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®š
            # stream=True,
            )
            # print(completion.choices[0].message.content)
            print("API Response:", completion)  # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            return completion.choices[0].message.content.strip()

        except Exception as e:
            print("API Error:", e)  # ã‚¨ãƒ©ãƒ¼å‡ºåŠ›
            return f"ã‚¨ãƒ©ãƒ¼: {e}\n ç®¡ç†è€…ã¸å ±å‘Šã—ã¦ãã ã•ã„"


    messages = st.session_state.get('messages', [])
        # print(messages)

    # ä¼šè©±ã®å±¥æ­´ã‚’è¡¨ç¤º
    for message in messages:
        # AIã‹ã‚‰ã®å›ç­”ã®å ´åˆ
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)
        # ãã‚Œä»¥å¤–ï¼ˆã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã‹ï¼‰
        else:  # isinstance(message, SystemMessage):
            st.write(f"System message: {message.content}")

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®çŠ¶æ…‹ã«åŸºã¥ã„ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    feedback = st.session_state.get('feedback', None)  # feedbackã‚­ãƒ¼ãŒãªã‘ã‚Œã°Noneã‚’è¿”ã™
    if feedback == "good":
        with st.chat_message(''):
            st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™")
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒgoodã§ã€ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ã‹ãªã„å›ç­”ã ã£ãŸå ´åˆã«è³ªå•ã¨å›ç­”ã‚’è¨˜éŒ²
            append_to_scenario(st.session_state.get('current_question', ''), st.session_state.get('current_response', ''))
            st.session_state['feedback']=[]
            print('append_to_scenario & feedback_reset')

    elif feedback == "bad":
        with st.chat_message(''):
            st.error("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™")
            st.session_state['feedback']=[]
            print('bad feedback')
        # feedbackã‚­ãƒ¼ãŒãªã„å ´åˆã‚„ã€'good'/'bad'ä»¥å¤–ã®å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

    # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®åˆæœŸå€¤
    user_input = st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼")
    scenario_df = load_scenarios()
    if scenario_df is None:
        print("ã‚·ãƒŠãƒªã‚ªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿errorç™ºç”Ÿ")
        exit
    if user_input: # è³ªå•ãŒæ¥ãŸã‚‰å‡¦ç†é–‹å§‹
        # print(user_input)

        # å¿œç­”ç”Ÿæˆé–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        start_time = time.time()
        if st.session_state['stop']:
        # æ–°ã—ã„å…¥åŠ›ãŒã‚ã‚‹å ´åˆã€å¼·åˆ¶åœæ­¢çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state['stop'] = False
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å±¥æ­´ã«è¿½åŠ 
        st.session_state.messages.append(HumanMessage(content=user_input))
        # è³ªå•å†…å®¹ã‚’ç”»é¢ã«è¡¨ç¤º
        st.chat_message("user").markdown(user_input)

        # å›ç­”ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹
        closest_match, scenario_response, is_scenario_based = get_closest_match(user_input, scenario_df)
        with st.spinner("å›ç­”ç”Ÿæˆä¸­"):
            # with st.chat_message('assistant',avatar=img_beorder):
            with st.chat_message('assistant'):
                if is_scenario_based :
                    print('ã‚·ãƒŠãƒªã‚ªã‚ã‚Š')
                    response = scenario_response + "(ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ãå›ç­”)"
                else:
                    print('ã‚·ãƒŠãƒªã‚ªãªã—')
                    response = conversational_chat_whth_fallback(user_input)
                # print(response)
                # å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append(AIMessage(content=response))
                # print(messages)
                # å›ç­”ã‚’ç”»é¢ã«è¡¨ç¤º
                st.markdown(response)
                
        # å›ç­”æ™‚é–“ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹
        end_time = time.time() 
        duration = end_time - start_time

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†
        col1, col2 = st.columns(2)
        def on_good_button_clicked():
            st.session_state['feedback'] = 'good'
            st.session_state['feedback_given'] = True
            
        def on_bad_button_clicked():
            st.session_state['feedback'] = 'bad'
            st.session_state['feedback_given'] = True

        # ä¼šè©±ã®å±¥æ­´ã‚’æ›´æ–°ã™ã‚‹å‰ã«ç¾åœ¨ã®è³ªå•ã¨å›ç­”ã‚’session_stateã«ä¿å­˜
        st.session_state['current_question'] = user_input
        st.session_state['current_response'] = response
        st.session_state['is_scenario_based'] = is_scenario_based

        if col1.button("è‰¯ã‹ã£ãŸ ğŸ‘",on_click=on_good_button_clicked):
            pass
        if col2.button("ã‚¤ãƒã‚¤ãƒ ğŸ‘",on_click=on_bad_button_clicked):
            pass
        
        st.info(f'å¿œç­”ã«ã‹ã‹ã£ãŸæ™‚é–“ï¼š{duration:.2f}ç§’')

        if st.session_state.get('feedback', '') == 'good' and not is_scenario_based:
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒgoodã§ã€ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ã‹ãªã„å›ç­”ã ã£ãŸå ´åˆ
            append_to_scenario(user_input, response)

        st.session_state['feedback'] = None

        save_chat_log(user_input,response,None) # ãƒ­ã‚°ä¿å­˜

    elif st.session_state['stop']:
        st.error("å¿œç­”ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ")

if __name__ == '__main__':
    main()